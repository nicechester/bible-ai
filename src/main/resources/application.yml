spring:
  application:
    name: Bible-AI

langchain4j:
  llm:
    provider: ${LLM_PROVIDER:gemini}  # Options: gemini or llama
    gemini:
      model-name: ${GEMINI_MODEL_NAME:gemini-2.5-flash-lite}
      api-key: ${GEMINI_API_KEY:}
  splitter:
    text:
      maxSegmentSize: 500
      maxOverlapSize: 50

# Llama configuration
llm:
  model:
    path: ${LLAMA_MODEL_PATH:classpath:models/model.gguf}  # Path to .gguf model file (default: models directory under resources)
    ngpu: ${LLAMA_NGPU_LAYERS:0}  # Number of GPU layers (0 = CPU only)
    temperature: ${LLAMA_TEMPERATURE:0.7}

bible:
  data:
    json-path: ${BIBLE_JSON_PATH:classpath:bible/bible_krv.json}
    asv-json-path: ${BIBLE_ASV_JSON_PATH:classpath:bible/bible_asv.json}
  rag:
    max-results: 3
    min-score: 0.6

management:
  endpoints:
    web:
      exposure:
        include: health,info
  endpoint:
    health:
      show-details: when-authorized
      show-components: always

