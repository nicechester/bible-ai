spring:
  application:
    name: Bible-AI

langchain4j:
  llm:
    provider: ${LLM_PROVIDER:gemini}  # Options: gemini or llama
    gemini:
      model-name: ${GEMINI_MODEL_NAME:gemini-2.5-flash-lite}
      api-key: ${GEMINI_API_KEY:}
  splitter:
    text:
      maxSegmentSize: 500
      maxOverlapSize: 50

# Llama configuration
llm:
  model:
    path: ${LLAMA_MODEL_PATH:classpath:models/model.gguf}  # Path to .gguf model file (default: models directory under resources)
    ngpu: ${LLAMA_NGPU_LAYERS:0}  # Number of GPU layers (0 = CPU only)
    temperature: ${LLAMA_TEMPERATURE:0.7}

bible:
  data:
    json-path: ${BIBLE_JSON_PATH:classpath:bible/bible_krv.json}
    asv-json-path: ${BIBLE_ASV_JSON_PATH:classpath:bible/bible_asv.json}
  rag:
    max-results: 3
    min-score: 0.6
  # Embedding store configuration (SQLite preferred for fast cold starts)
  embedding:
    sqlite:
      enabled: ${EMBEDDING_SQLITE_ENABLED:false}
      path: ${EMBEDDING_SQLITE_PATH:classpath:embeddings/bible-embeddings.db}
    gcs:
      enabled: ${EMBEDDING_GCS_ENABLED:false}
      bucket: ${EMBEDDING_GCS_BUCKET:bible-ai-embeddings}
      blob-name: ${EMBEDDING_GCS_BLOB:embeddings/bible-embeddings.json}
  # Smart search configuration
  search:
    candidate-count: ${SEARCH_CANDIDATE_COUNT:50}
    result-count: ${SEARCH_RESULT_COUNT:10}
    min-score: ${SEARCH_MIN_SCORE:0.3}

management:
  endpoints:
    web:
      exposure:
        include: health,info
  endpoint:
    health:
      show-details: when-authorized
      show-components: always

